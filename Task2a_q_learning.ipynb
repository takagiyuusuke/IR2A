{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takagiyuusuke/IR2A/blob/main/Task2a_q_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5ZqqJvRW94P"
      },
      "source": [
        "# 知能ロボティクス実験 Task2aのための強化学習プログラム\n",
        " 制作: 髙木裕輔 (December,2024)\n",
        "\n",
        "---\n",
        "\n",
        "## 概要\n",
        "本プロジェクトでは、Q学習 (Q-learning)を使用して知能ロボティクス実験のTask2aで安全な経路を発見するエージェントを開発する。以下のステップに従って学習を行う:\n",
        "\n",
        "- シミュレータの実装\n",
        "- Qエージェントの定義\n",
        "- 訓練環境の定義\n",
        "- 学習の実行と結果の可視化\n",
        "\n",
        "コードブロックを順に実行することで学習を行い、結果を可視化することが可能となっている。\n",
        "\n",
        "---\n",
        "\n",
        "## タスクの詳細\n",
        "Task2aを以下のように簡略化します。\n",
        "\n",
        "### 凡例:\n",
        "- 📍: スタート\n",
        "- 🚩: ゴール\n",
        "- 🟧: 壁\n",
        "- 🟥: 障害物(特定の位置にランダムに生成される)\n",
        "\n",
        "### 盤面の例:\n",
        "⬜ ⬜ ⬜ 🟧 ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ 🚩  \n",
        "⬜ ⬜ ⬜ 🟧 ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ 🚩  \n",
        "⬜ ⬜ ⬜ 🟧 ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ 🚩  \n",
        "⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ 🚩  \n",
        "⬜ ⬜ ⬜ ⬜ 🟥 ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ 🚩  \n",
        "⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ 🚩  \n",
        "⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ 🚩  \n",
        "⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ 🟥 ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ 🚩  \n",
        "📍 ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ 🚩  \n",
        "⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ 🚩  \n",
        "⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ 🚩  \n",
        "⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ 🚩  \n",
        "⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ 🚩  \n",
        "⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ 🚩  \n",
        "⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ 🚩  \n",
        "🟧 🟧 🟧 🟧 🟧 🟧 🟧 🟧 🟧 🟧 🟧 🟧 🟧 🟧 🟧 🟧 🟧\n",
        "\n",
        "### エージェントの行動:\n",
        "エージェントが🟦の位置にいるときに🟩の位置に移動することができる(上下に2マス以内、右に1マス)。  \n",
        "ただし、領域外に移動することはできない。  \n",
        "⬜ ⬜ ⬜ ⬜  \n",
        "⬜ ⬜ 🟩 ⬜  \n",
        "⬜ ⬜ 🟩 ⬜  \n",
        "⬜ 🟦 🟩 ⬜  \n",
        "⬜ ⬜ 🟩 ⬜  \n",
        "⬜ ⬜ 🟩 ⬜  \n",
        "⬜ ⬜ ⬜ ⬜\n",
        "\n",
        "\n",
        "### 目標:\n",
        "スタートからゴールまで壁や障害物からの距離を最大化しながら辿る\n",
        "\n",
        "---\n",
        "\n",
        "## 参考文献\n",
        "このファイルは以下を参考に作成した。\n",
        "- 杉浦孔明教授 機械学習基礎 強化学習の基礎 実習 (閲覧にはkeio.jpの認証が必要)\n",
        "\n",
        "    https://colab.research.google.com/drive/1-wz31FTjB5o9EKl1gtueZ3pf2ZC7mo1A?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUSMkKlA42TN"
      },
      "source": [
        "# 0. インポート・乱数シードの設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-14IUw2d2_QA"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import time\n",
        "import math\n",
        "from typing import Literal, Tuple, List\n",
        "\n",
        "random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99T-14SE5Bpw"
      },
      "source": [
        "# 1. simulatorのロジック\n",
        "ロボットが安全な経路をたどるタスクを定義する"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ykesHKTt4zjC"
      },
      "outputs": [],
      "source": [
        "class Simulator:\n",
        "    \"\"\"Task2aをシミュレーションするクラス.\n",
        "\n",
        "    display=Trueにしてインスタンスを生成すると、\n",
        "    modiify_board()関数により変更した際に自動で毎回盤面が表示される\n",
        "    なお、print_board()をdisplay_forceオプションをつけて呼び出せば\n",
        "    強制的に盤面が表示されることが可能である\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    display : bool\n",
        "        盤面を画面に表示するか否か\n",
        "    interval : int or float\n",
        "        表示する場合、処理と処理の間隔(秒)\n",
        "\n",
        "    Public Methods:\n",
        "    -------\n",
        "    reset_game() -> None\n",
        "        ゲームをリセットする.\n",
        "    print_board(display_force: bool = False) -> None\n",
        "        ゲームの盤面を表示する.\n",
        "    is_gameover() -> bool\n",
        "        ゲームオーバーかどうかを判定する.\n",
        "    get_state() -> Tuple[int, Tuple[int]]\n",
        "        盤面と落下中のブロックの形状などを返す.\n",
        "    get_possible_actions() -> List[int]\n",
        "        エージェントに渡す可能な行動を返す.\n",
        "    get_score() -> float\n",
        "        現在の得点を返す.\n",
        "    modify_board(action: int) -> None\n",
        "        エージェントからの行動を受け取り内部状態の変更を行う\n",
        "    \"\"\"\n",
        "\n",
        "    # 盤面のパラメータ\n",
        "    _BOARD_HEIGHT = 15\n",
        "    _BOARD_WIDTH = 15\n",
        "\n",
        "    def __init__(self, display: bool, interval: int | float = 0) -> None:\n",
        "        self.display = display\n",
        "        self.interval = interval\n",
        "        self.reset_game()\n",
        "\n",
        "    def reset_game(self) -> None:\n",
        "        \"\"\"ゲームをリセットする.\"\"\"\n",
        "        self.board = self._random_board()\n",
        "        self.x = 8\n",
        "        self.y = -1\n",
        "        self.distance = 0\n",
        "        self.calculate_distance()\n",
        "        self.way = []\n",
        "\n",
        "    def _random_board(self) -> list:\n",
        "        \"\"\"障害物をランダムに配置したリストを返す.\"\"\"\n",
        "        if random.random() < 0.001:\n",
        "            x = random.randint(3, self._BOARD_HEIGHT - 1)\n",
        "            y = random.randint(2, self._BOARD_WIDTH - 2)\n",
        "            return [[x, y]]\n",
        "        else:\n",
        "            x1 = random.randint(3, self._BOARD_HEIGHT - 1)\n",
        "            y1 = random.randint(2, self._BOARD_WIDTH - 2)\n",
        "            x2 = random.randint(3, self._BOARD_HEIGHT - 1)\n",
        "            y2 = random.randint(2, self._BOARD_WIDTH - 2)\n",
        "            while (x1 == x2 and y1 == y2):\n",
        "                x2 = random.randint(3, self._BOARD_HEIGHT - 1)\n",
        "                y2 = random.randint(2, self._BOARD_WIDTH - 2)\n",
        "            return sorted([[x1, y1], [x2, y2]])\n",
        "\n",
        "    def print_board(self, display_force: bool = False) -> None:\n",
        "        \"\"\"ゲームの盤面を表示する.\n",
        "\n",
        "        Parameters:\n",
        "        ----------\n",
        "        display_force : bool\n",
        "            強制的に盤面を表示するかどうか\n",
        "        \"\"\"\n",
        "        if not display_force and not self.display:\n",
        "            return\n",
        "        board = \"\\n\"\n",
        "        for i in range(self._BOARD_HEIGHT):\n",
        "            if i == 8:\n",
        "                board += \"📍\"\n",
        "            else:\n",
        "                board += \"⬜\"\n",
        "            for j in range(self._BOARD_WIDTH):\n",
        "                if [i, j] in [[0, 2], [1, 2], [2, 2]] :\n",
        "                    board += \"🟧\"\n",
        "                elif [i, j] == [self.x, self.y]:\n",
        "                    board += \"🟩\"\n",
        "                elif [i, j] in self.board:\n",
        "                    board += \"🟥\"\n",
        "                elif [i, j] in self.way:\n",
        "                    board += \"🟦\"\n",
        "                else:\n",
        "                    board += \"⬜\"\n",
        "            board += (\"🚩\\n\")\n",
        "        board += (\"🟧\" * (self._BOARD_WIDTH + 2))\n",
        "        print(board)\n",
        "        time.sleep(self.interval)\n",
        "\n",
        "\n",
        "    def _move_right(self) -> None:\n",
        "        \"\"\"右に1マス移動する\"\"\"\n",
        "        self.y += 1\n",
        "\n",
        "    def _move_down(self) -> None:\n",
        "        \"\"\"右に1マス、下に1マス移動する\"\"\"\n",
        "        self.x += 1\n",
        "        self.y += 1\n",
        "\n",
        "    def _move_up(self) -> None:\n",
        "        \"\"\"右に1マス、上に1マス移動する\"\"\"\n",
        "        self.x -= 1\n",
        "        self.y += 1\n",
        "\n",
        "    def _move_down2(self) -> None:\n",
        "        \"\"\"右に1マス、下に2マス移動する\"\"\"\n",
        "        self.x += 2\n",
        "        self.y += 1\n",
        "\n",
        "    def _move_up2(self) -> None:\n",
        "        \"\"\"右に1マス、上に2マス移動する\"\"\"\n",
        "        self.x -= 2\n",
        "        self.y += 1\n",
        "\n",
        "    def is_gameover(self) -> bool:\n",
        "        \"\"\"ゲームオーバーならTrueを返す.\"\"\"\n",
        "        return self.y >= self._BOARD_WIDTH - 1\n",
        "\n",
        "    def get_state(self) -> Tuple[int, Tuple[int]]:\n",
        "        \"\"\"盤面と現在地をまとめて状態として返す\"\"\"\n",
        "        board_num = 0\n",
        "        for element in self.board:\n",
        "            board_num = board_num * 10000 + element[0] * 100 + element[1]\n",
        "        return (board_num, (self.x, self.y))\n",
        "\n",
        "    def get_possible_actions(self) -> List[int]:\n",
        "        \"\"\"エージェントに渡す可能な行動を返す.\"\"\"\n",
        "        possible_actions = [2]\n",
        "        if self.x < self._BOARD_HEIGHT - 1:\n",
        "            possible_actions.append(0)\n",
        "        if self.x > 0:\n",
        "            possible_actions.append(1)\n",
        "        if self.x < self._BOARD_HEIGHT - 2:\n",
        "            possible_actions.append(3)\n",
        "        if self.x > 1:\n",
        "            possible_actions.append(4)\n",
        "\n",
        "        return possible_actions\n",
        "\n",
        "    def get_score(self) -> float:\n",
        "        \"\"\"現在の得点を返す.\"\"\"\n",
        "        return self.distance\n",
        "\n",
        "    def calculate_distance(self) -> None:\n",
        "        \"\"\"現在地から最寄りの障害物・壁までの距離を計算する.\"\"\"\n",
        "        distance = min(\n",
        "            (self._BOARD_HEIGHT - self.x),\n",
        "            math.sqrt((self.x - 3) ** 2 + (self.y - 2) ** 2)\n",
        "        )\n",
        "        for element in self.board:\n",
        "            dif_x = element[0] - self.x\n",
        "            dif_y = element[1] - self.y\n",
        "            dist = math.sqrt(dif_x**2 + dif_y**2)\n",
        "            if dist < distance:\n",
        "                distance = dist\n",
        "        if distance == 0:\n",
        "            self.distance -= 2\n",
        "        else:\n",
        "            self.distance -= 1 / distance\n",
        "\n",
        "    def modify_board(self, action: int) -> None:\n",
        "        \"\"\"エージェントからの行動を受け取り内部状態の変更を行う.\"\"\"\n",
        "        if self.display:\n",
        "            self.way.append([self.x, self.y])\n",
        "        if action == 0:\n",
        "            self._move_down()\n",
        "        elif action == 1:\n",
        "            self._move_up()\n",
        "        elif action == 2:\n",
        "            self._move_right()\n",
        "        elif action == 3:\n",
        "            self._move_down2()\n",
        "        elif action == 4:\n",
        "            self._move_up2()\n",
        "        self.print_board()\n",
        "\n",
        "        self.calculate_distance()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT2hfnFqv0fn"
      },
      "source": [
        "# 2. Agentの定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtUz7BHev5Vg"
      },
      "outputs": [],
      "source": [
        "class Agent:\n",
        "    def __init__(self):\n",
        "        self.frozen = False\n",
        "\n",
        "    def train(self):\n",
        "        self.frozen = False\n",
        "\n",
        "    def eval(self):\n",
        "        self.frozen = True\n",
        "\n",
        "    def _observe(self, simulator: Simulator):\n",
        "        return simulator.get_state()\n",
        "\n",
        "    def action(self, simulator: Simulator):\n",
        "        pass\n",
        "\n",
        "    def update(self, simulator: Simulator, state, action, reward1, new_state):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7mPs5Kw62EH"
      },
      "source": [
        "## 2-1. Qエージェントの定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12vTrWXa68iM"
      },
      "outputs": [],
      "source": [
        "class QAgent(Agent):\n",
        "    def __init__(self, lr: float, eps=0.3):\n",
        "        super().__init__()\n",
        "        self.q_table = {}  # Qテーブルの初期化\n",
        "        self.discount_factor = 0.85\n",
        "        self.learning_rate = lr\n",
        "        self.epsilon = eps\n",
        "\n",
        "    def action(\n",
        "            self, simulator: Simulator,\n",
        "            state: Tuple[List[int], List[int]]\n",
        "            ):\n",
        "        possible_actions = simulator.get_possible_actions()\n",
        "        if not self.frozen and random.random() < self.epsilon:\n",
        "            return random.choice(possible_actions)\n",
        "        else:\n",
        "            best_action, _ = self._get_the_best(state, possible_actions)\n",
        "            return best_action\n",
        "\n",
        "    def _get_the_best(self, state, possible_moves):\n",
        "        q_board = state[0]\n",
        "        q_block = state[1]\n",
        "\n",
        "        best_move = None\n",
        "        best_q_value = -float('inf')\n",
        "        for move in possible_moves:\n",
        "            q_value = self.q_table.get((q_board, q_block, move), 0)\n",
        "            if q_value > best_q_value:\n",
        "                best_q_value = q_value\n",
        "                best_move = move\n",
        "        return best_move, best_q_value\n",
        "\n",
        "    def update(self, simulator, state, action, reward, next_state):\n",
        "        if self.frozen:\n",
        "            return None\n",
        "\n",
        "        q_board = state[0]\n",
        "        q_block = state[1]\n",
        "        n_q_board = next_state[0]\n",
        "        n_q_block = next_state[1]\n",
        "\n",
        "        old_value = self.q_table.get((q_board, q_block, action), 0)\n",
        "        possible_moves = simulator.get_possible_actions()\n",
        "\n",
        "        assert next_state is not None\n",
        "        next_max = max([\n",
        "            self.q_table.get((n_q_board, n_q_block, next_action), 0)\n",
        "            for next_action in possible_moves])\n",
        "\n",
        "        new_value = old_value + self.learning_rate * \\\n",
        "            (reward + self.discount_factor * next_max - old_value)\n",
        "        if new_value != 0:  # new_valueが0のときはq_tavleに追加しなくてもOK\n",
        "            self.q_table[(q_board, q_block, action)] = new_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XKtwL2jK8XX"
      },
      "source": [
        "# 3. Env."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_J1ulA5LBGM"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "import plotly.graph_objects as go\n",
        "import statistics\n",
        "\n",
        "\n",
        "class Env:\n",
        "    def __init__(self, agent: Agent, simulator: Simulator) -> None:\n",
        "        self.agent = agent\n",
        "        self.simulator = simulator\n",
        "\n",
        "    def _get_reward(self) -> int:\n",
        "        score = self.simulator.get_score()\n",
        "        return score\n",
        "\n",
        "    def train(self, episodes: int, visualize=False):  # Nエピソード実行\n",
        "        record = []\n",
        "        for i in tqdm.tqdm(range(episodes)):\n",
        "            score = self.execute(train=True, visualize=visualize)\n",
        "            record.append(self._get_reward())\n",
        "            if (i + 1) % int(episodes / 10) == 0:\n",
        "                self.simulator.print_board(display_force=True)\n",
        "                print(\"Episode: from {} to {}\".format(\n",
        "                    i + 1 - int(episodes / 10), i))\n",
        "                print(\"Average Score: {}\".format(\n",
        "                    (sum(record[-int(episodes / 10):])/int(episodes / 10))))\n",
        "                print(\"Max Score:     {}\".format(\n",
        "                    max(record[-int(episodes / 10):])))\n",
        "                print(\"Median Score:  {}\".format(\n",
        "                    statistics.median_low(record[-int(episodes / 10):])))\n",
        "        print(\"Report:\")\n",
        "        return record\n",
        "\n",
        "    def execute(self, train=False, visualize=True):  # 1 episode\n",
        "        self.simulator.reset_game()\n",
        "\n",
        "        while not self.simulator.is_gameover():\n",
        "            state = self.simulator.get_state()\n",
        "            before_point = self.simulator.get_score()\n",
        "            action = self.agent.action(self.simulator, state)\n",
        "            self.simulator.modify_board(action)\n",
        "            after_point = self.simulator.get_score()\n",
        "            if train:\n",
        "                reward = after_point - before_point\n",
        "                next_state = self.simulator.get_state()\n",
        "                if simulator.is_gameover():\n",
        "                    reward = +10\n",
        "\n",
        "                self.agent.update(self.simulator, state,\n",
        "                                  action, reward, next_state)\n",
        "\n",
        "        # game end\n",
        "        score = self.simulator.get_score()\n",
        "\n",
        "        return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ssv8Pt5XKlf"
      },
      "source": [
        "# 4. Q学習\n",
        "学習中、現状確認のために全体の10%が完了する毎に終了時の盤面が出力される"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-GYzUSlXMRb"
      },
      "outputs": [],
      "source": [
        "q_agent = QAgent(lr=0.5, eps=0.1)\n",
        "q_agent.epsilon = 0.25 #はじめ、εはこのくらい大きめの方が経験的に良い\n",
        "simulator = Simulator(False)\n",
        "env = Env(q_agent, simulator)\n",
        "record = env.train(1000000) #訓練するエピソード数\n",
        "fig = go.Figure(data=go.Scatter(y=record))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlmCVNaBGgaX"
      },
      "source": [
        "# 5. 学習が完了したQエージェントにプレイさせる\n",
        "モデルが実際にどのようなプレイをするのか確かめる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1d3DNsi7GKZC"
      },
      "outputs": [],
      "source": [
        "q_agent.eval()\n",
        "env = Env(q_agent, Simulator(True, interval = 0.25))\n",
        "for i in range(10):\n",
        "    env.execute()\n",
        "q_agent.train()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "du2UGARBvXuq"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}